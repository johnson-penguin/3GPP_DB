{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f3e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from datetime import datetime\n",
    "TeleQnA = \"C:/Users/wasd0/Desktop/AMD-AI-Agent-Online-Hackthon/branchmark/TeleQnA/TeleQnA.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b765787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]',\n",
       " 'option 1': 'To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints',\n",
       " 'option 2': 'To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints',\n",
       " 'option 3': 'To supply data or analytics from the MFAF to notification endpoints',\n",
       " 'option 4': 'To fetch data or analytics from the MFAF based on fetch instructions',\n",
       " 'answer': 'option 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints',\n",
       " 'explanation': 'The Nmfaf_3daDataManagement_Deconfigure service operation is used to stop mapping data or analytics received by the MFAF to one or more out-bound notification endpoints.',\n",
       " 'category': 'Standards specifications'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(TeleQnA, \"r\", encoding=\"utf-8\") as f:\n",
    "    teleqna_data = json.load(f)\n",
    "\n",
    "# È°ØÁ§∫‰∏ÄÁ≠ÜË≥áÊñôÁØÑ‰æã\n",
    "sample_key = list(teleqna_data.keys())[0]\n",
    "teleqna_data[sample_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65dec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_nvidia_llm(prompt: str) -> str:\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key = \"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\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"microsoft/phi-4-mini-flash-reasoning\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# üì§ ÁîüÊàê prompt ‰∏¶ÂèñÂæóÂõûÊáâ\n",
    "def generate_prompt(entry: dict) -> str:\n",
    "    prompt = f\"\"\"You are a telecom expert. Please answer the following multiple choice question with an explanation.\n",
    "\n",
    "Question: {entry['question']}\n",
    "\n",
    "Options:\n",
    "(A) {entry['option 1']}\n",
    "(B) {entry['option 2']}\n",
    "(C) {entry['option 3']}\n",
    "(D) {entry['option 4']}\n",
    "\n",
    "Please provide:\n",
    "1. The correct option (A/B/C/D)\n",
    "2. A brief explanation.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6058503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ÂõûÊáâÂÖßÂÆπ:\n",
      " <think>['1. **Identify the core concept:** The question is about the Alamouti scheme and its diversity gain.\\n\\n2. **Recall knowledge about Alamouti scheme:**  The Alamouti scheme is a direct detection method used in MDS codes. Its primary goal is *to simplify detection* of symbols, particularly in the presence of amplitude modulation.\\n\\n3. **Connect \"simplify detection\" to diversity gain:**  A diversity gain in detection means the ability to distinguish between multiple signals or symbols. While the Alamouti scheme performs detection, the *diversity gain* isn\\'t its main purpose.\\n\\n4. **Eliminate incorrect options:**\\n    * (A) 0: A diversity gain of 0 means no ability to distinguish, which contradicts the purpose of the Alamouti scheme.\\n    * (D) 1: While it might seem like the basic detection capability is one unit, the key aspect is *improvement* in detection due to diversity.\\n\\n5. **Focus on the \"simplicity\" aspect:** The Alamouti scheme simplifies detection. This simplification *directly* leads to an increase in the ability to distinguish symbols compared to direct detection.\\n\\n6. **Consider the MDS code structure:** MDS codes have multiple, interleaved data streams. The Alamouti scheme *receives* these interleaved signals but decodes them by treating them as if they were received individually. This interference enhances detection.\\n\\n7. **Recognize the multiplication effect:** The interleaving data and the simplification of detection interact to provide a significantly improved ability to detect each symbol compared to the standard detection scheme.\\n\\n8. **Confirm the answer:** The increased detection capability due to the interleaving and the simplification of detection by the Alamouti scheme is typically considered a diversity gain of 2. This aligns with the idea of \"simpler, but *twice as* effective\" detection.\\n\\n9. **Final Answer:**  (C) 2\\n\\n10. **Refine explanation:**  Explain *why* 2 is the correct answer (simplified detection of interleaved signals leading to improved distinguishability) and why the other options are incorrect.']</think>BC\n"
     ]
    }
   ],
   "source": [
    "# üîÑ Ê∏¨Ë©¶‰∏ÄÁ≠ÜË≥áÊñô\n",
    "entry = teleqna_data[\"question 2\"]\n",
    "prompt = generate_prompt(entry)\n",
    "llm_response = call_nvidia_llm(prompt)\n",
    "print(\"LLM ÂõûÊáâÂÖßÂÆπ:\\n\", llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8def870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_guess': 'A',\n",
       " 'correct_letter': 'C',\n",
       " 'is_correct': False,\n",
       " 'llm_explanation': '<think>[\\'1. **Identify the core concept:** The question is about the Alamouti scheme and its diversity gain.\\\\n\\\\n2. **Recall knowledge about Alamouti scheme:**  The Alamouti scheme is a direct detection method used in MDS codes. Its primary goal is *to simplify detection* of symbols, particularly in the presence of amplitude modulation.\\\\n\\\\n3. **Connect \"simplify detection\" to diversity gain:**  A diversity gain in detection means the ability to distinguish between multiple signals or symbols. While the Alamouti scheme performs detection, the *diversity gain* isn\\\\\\'t its main purpose.\\\\n\\\\n4. **Eliminate incorrect options:**\\\\n    * (A) 0: A diversity gain of 0 means no ability to distinguish, which contradicts the purpose of the Alamouti scheme.\\\\n    * (D) 1: While it might seem like the basic detection capability is one unit, the key aspect is *improvement* in detection due to diversity.\\\\n\\\\n5. **Focus on the \"simplicity\" aspect:** The Alamouti scheme simplifies detection. This simplification *directly* leads to an increase in the ability to distinguish symbols compared to direct detection.\\\\n\\\\n6. **Consider the MDS code structure:** MDS codes have multiple, interleaved data streams. The Alamouti scheme *receives* these interleaved signals but decodes them by treating them as if they were received individually. This interference enhances detection.\\\\n\\\\n7. **Recognize the multiplication effect:** The interleaving data and the simplification of detection interact to provide a significantly improved ability to detect each symbol compared to the standard detection scheme.\\\\n\\\\n8. **Confirm the answer:** The increased detection capability due to the interleaving and the simplification of detection by the Alamouti scheme is typically considered a diversity gain of 2. This aligns with the idea of \"simpler, but *twice as* effective\" detection.\\\\n\\\\n9. **Final Answer:**  (C) 2\\\\n\\\\n10. **Refine explanation:**  Explain *why* 2 is the correct answer (simplified detection of interleaved signals leading to improved distinguishability) and why the other options are incorrect.\\']</think>BC'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîç ÊØîÂ∞ç LLM ÂõûÁ≠îËàáÊ≠£Ëß£\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def match_option(llm_output: str, correct_answer: str) -> dict:\n",
    "    correct_option = correct_answer.split(\":\")[0].strip().split()[-1]  # option 3 ‚Üí 3\n",
    "    correct_letter = chr(ord(\"A\") + int(correct_option) - 1)  # 3 ‚Üí C\n",
    "\n",
    "    llm_guess = \"?\"\n",
    "    for letter in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        if f\"({letter})\" in llm_output or f\"Option {letter}\" in llm_output or f\"Answer: {letter}\" in llm_output:\n",
    "            llm_guess = letter\n",
    "            break\n",
    "\n",
    "    is_correct = (llm_guess == correct_letter)\n",
    "\n",
    "    return {\n",
    "        \"llm_guess\": llm_guess,\n",
    "        \"correct_letter\": correct_letter,\n",
    "        \"is_correct\": is_correct,\n",
    "        \"llm_explanation\": llm_output\n",
    "    }\n",
    "\n",
    "match_result = match_option(llm_response, entry[\"answer\"])\n",
    "match_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e7f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "def evaluate_model_on_teleqna(model_name: str, num_questions: int = 10, delay_sec: int = 2):\n",
    "    print(f\"\\nüöÄ Testing model: {model_name}\")\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=\"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\"\n",
    "    )\n",
    "\n",
    "    correct_count = 0\n",
    "    results = []\n",
    "    all_keys = list(teleqna_data.keys())[:num_questions]\n",
    "\n",
    "    for idx, key in enumerate(all_keys, start=1):\n",
    "        entry = teleqna_data[key]\n",
    "        prompt = generate_prompt(entry)\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.5,\n",
    "                top_p=0.7,\n",
    "                max_tokens=1024,\n",
    "                stream=False\n",
    "            )\n",
    "            llm_response = response.choices[0].message.content\n",
    "\n",
    "            result = match_option(llm_response, entry[\"answer\"])\n",
    "            result[\"question_key\"] = key\n",
    "            results.append(result)\n",
    "\n",
    "            if result[\"is_correct\"]:\n",
    "                correct_count += 1\n",
    "\n",
    "            current_accuracy = correct_count / idx\n",
    "            status = \"‚úÖ Correct\" if result[\"is_correct\"] else \"‚ùå Wrong\"\n",
    "            print(f\"[{idx:02}] {status} | Guess: {result['llm_guess']} | Ans: {result['correct_letter']} | Acc: {current_accuracy:.2%}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx:02}] ‚ö†Ô∏è Error in question {key}: {e}\")\n",
    "            results.append({\"question_key\": key, \"error\": str(e)})\n",
    "\n",
    "        time.sleep(delay_sec)\n",
    "\n",
    "    final_accuracy = correct_count / len(all_keys)\n",
    "    print(f\"üéØ Final Accuracy for {model_name}: {final_accuracy:.2%}\")\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": final_accuracy,\n",
    "        \"results\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f2da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Testing model: meta/llama-3.1-8b-instruct\n",
      "[01] ‚úÖ Correct | Guess: B | Ans: B | Acc: 100.00%\n",
      "[02] ‚ùå Wrong | Guess: D | Ans: E | Acc: 50.00%\n",
      "[03] ‚úÖ Correct | Guess: C | Ans: C | Acc: 66.67%\n",
      "[04] ‚ùå Wrong | Guess: A | Ans: D | Acc: 50.00%\n",
      "[05] ‚ùå Wrong | Guess: A | Ans: B | Acc: 40.00%\n",
      "[06] ‚úÖ Correct | Guess: C | Ans: C | Acc: 50.00%\n",
      "[07] ‚úÖ Correct | Guess: B | Ans: B | Acc: 57.14%\n",
      "[08] ‚úÖ Correct | Guess: A | Ans: A | Acc: 62.50%\n",
      "[09] ‚úÖ Correct | Guess: A | Ans: A | Acc: 66.67%\n",
      "[10] ‚úÖ Correct | Guess: B | Ans: B | Acc: 70.00%\n",
      "[11] ‚ùå Wrong | Guess: A | Ans: C | Acc: 63.64%\n",
      "[12] ‚úÖ Correct | Guess: C | Ans: C | Acc: 66.67%\n",
      "[13] ‚úÖ Correct | Guess: D | Ans: D | Acc: 69.23%\n",
      "[14] ‚ùå Wrong | Guess: B | Ans: A | Acc: 64.29%\n",
      "[15] ‚ùå Wrong | Guess: A | Ans: B | Acc: 60.00%\n",
      "[16] ‚úÖ Correct | Guess: C | Ans: C | Acc: 62.50%\n",
      "[17] ‚ùå Wrong | Guess: D | Ans: E | Acc: 58.82%\n",
      "[18] ‚úÖ Correct | Guess: C | Ans: C | Acc: 61.11%\n",
      "[19] ‚úÖ Correct | Guess: A | Ans: A | Acc: 63.16%\n",
      "[20] ‚ùå Wrong | Guess: D | Ans: B | Acc: 60.00%\n",
      "üéØ Final Accuracy for meta/llama-3.1-8b-instruct: 60.00%\n",
      "Time taken for evaluation: 0:00:57.391951\n",
      "‚úÖ Saved to: C:\\Users\\wasd0\\Desktop\\AMD-AI-Agent-Online-Hackthon\\none-RAG_evaluation_results_20251202_224957.json\n"
     ]
    }
   ],
   "source": [
    "candidate_models = [\n",
    "# \"meta/llama-3.1-405b-instruct\",\n",
    "# \"meta/llama-3.1-70b-instruct\",\n",
    "\"meta/llama-3.1-8b-instruct\"\n",
    "]\n",
    "\n",
    "start_time = datetime.now()\n",
    "none_rag_results = []\n",
    "for model in candidate_models:\n",
    "    result = evaluate_model_on_teleqna(model_name=model, num_questions=20, delay_sec=0.5)\n",
    "    none_rag_results.append(result)\n",
    "\n",
    "\n",
    "data_to_save = none_rag_results\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "json_path = Path(f\"C:/Users/wasd0/Desktop/AMD-AI-Agent-Online-Hackthon/none-RAG_evaluation_results_{timestamp}.json\")\n",
    "end_time = datetime.now()\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for evaluation: {time_taken}\")\n",
    "\n",
    "\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_to_save, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved to: {json_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
