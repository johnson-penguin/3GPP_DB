{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f2d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-ai/yi-large \n",
      "abacusai/dracarys-llama-3.1-70b-instruct \n",
      "adept/fuyu-8b \n",
      "ai21labs/jamba-1.5-large-instruct \n",
      "ai21labs/jamba-1.5-mini-instruct \n",
      "aisingapore/sea-lion-7b-instruct \n",
      "baai/bge-m3 \n",
      "baichuan-inc/baichuan2-13b-chat \n",
      "bigcode/starcoder2-15b \n",
      "bigcode/starcoder2-7b \n",
      "bytedance/seed-oss-36b-instruct \n",
      "databricks/dbrx-instruct \n",
      "deepseek-ai/deepseek-coder-6.7b-instruct \n",
      "deepseek-ai/deepseek-r1 \n",
      "deepseek-ai/deepseek-r1-0528 \n",
      "deepseek-ai/deepseek-r1-distill-llama-8b \n",
      "deepseek-ai/deepseek-r1-distill-qwen-14b \n",
      "deepseek-ai/deepseek-r1-distill-qwen-32b \n",
      "deepseek-ai/deepseek-r1-distill-qwen-7b \n",
      "deepseek-ai/deepseek-v3.1 \n",
      "deepseek-ai/deepseek-v3.1-terminus \n",
      "google/codegemma-1.1-7b \n",
      "google/codegemma-7b \n",
      "google/deplot \n",
      "google/gemma-2-27b-it \n",
      "google/gemma-2-2b-it \n",
      "google/gemma-2-9b-it \n",
      "google/gemma-2b \n",
      "google/gemma-3-12b-it \n",
      "google/gemma-3-1b-it \n",
      "google/gemma-3-27b-it \n",
      "google/gemma-3-4b-it \n",
      "google/gemma-3n-e2b-it \n",
      "google/gemma-3n-e4b-it \n",
      "google/gemma-7b \n",
      "google/paligemma \n",
      "google/recurrentgemma-2b \n",
      "google/shieldgemma-9b \n",
      "gotocompany/gemma-2-9b-cpt-sahabatai-instruct \n",
      "ibm/granite-3.0-3b-a800m-instruct \n",
      "ibm/granite-3.0-8b-instruct \n",
      "ibm/granite-3.3-8b-instruct \n",
      "ibm/granite-34b-code-instruct \n",
      "ibm/granite-8b-code-instruct \n",
      "ibm/granite-guardian-3.0-8b \n",
      "igenius/colosseum_355b_instruct_16k \n",
      "igenius/italia_10b_instruct_16k \n",
      "institute-of-science-tokyo/llama-3.1-swallow-70b-instruct-v0.1 \n",
      "institute-of-science-tokyo/llama-3.1-swallow-8b-instruct-v0.1 \n",
      "marin/marin-8b-instruct \n",
      "mediatek/breeze-7b-instruct \n",
      "meta/codellama-70b \n",
      "meta/llama-3.1-405b-instruct \n",
      "meta/llama-3.1-70b-instruct \n",
      "meta/llama-3.1-8b-instruct \n",
      "meta/llama-3.2-11b-vision-instruct \n",
      "meta/llama-3.2-1b-instruct \n",
      "meta/llama-3.2-3b-instruct \n",
      "meta/llama-3.2-90b-vision-instruct \n",
      "meta/llama-3.3-70b-instruct \n",
      "meta/llama-4-maverick-17b-128e-instruct \n",
      "meta/llama-4-scout-17b-16e-instruct \n",
      "meta/llama-guard-4-12b \n",
      "meta/llama2-70b \n",
      "meta/llama3-70b-instruct \n",
      "meta/llama3-8b-instruct \n",
      "microsoft/kosmos-2 \n",
      "microsoft/phi-3-medium-128k-instruct \n",
      "microsoft/phi-3-medium-4k-instruct \n",
      "microsoft/phi-3-mini-128k-instruct \n",
      "microsoft/phi-3-mini-4k-instruct \n",
      "microsoft/phi-3-small-128k-instruct \n",
      "microsoft/phi-3-small-8k-instruct \n",
      "microsoft/phi-3-vision-128k-instruct \n",
      "microsoft/phi-3.5-mini-instruct \n",
      "microsoft/phi-3.5-moe-instruct \n",
      "microsoft/phi-3.5-vision-instruct \n",
      "microsoft/phi-4-mini-flash-reasoning \n",
      "microsoft/phi-4-mini-instruct \n",
      "microsoft/phi-4-multimodal-instruct \n",
      "minimaxai/minimax-m2 \n",
      "mistralai/codestral-22b-instruct-v0.1 \n",
      "mistralai/magistral-small-2506 \n",
      "mistralai/mamba-codestral-7b-v0.1 \n",
      "mistralai/mathstral-7b-v0.1 \n",
      "mistralai/ministral-14b-instruct-2512 \n",
      "mistralai/mistral-7b-instruct-v0.2 \n",
      "mistralai/mistral-7b-instruct-v0.3 \n",
      "mistralai/mistral-large \n",
      "mistralai/mistral-large-2-instruct \n",
      "mistralai/mistral-large-3-675b-instruct-2512 \n",
      "mistralai/mistral-medium-3-instruct \n",
      "mistralai/mistral-nemotron \n",
      "mistralai/mistral-small-24b-instruct \n",
      "mistralai/mistral-small-3.1-24b-instruct-2503 \n",
      "mistralai/mixtral-8x22b-instruct-v0.1 \n",
      "mistralai/mixtral-8x22b-v0.1 \n",
      "mistralai/mixtral-8x7b-instruct-v0.1 \n",
      "moonshotai/kimi-k2-instruct \n",
      "moonshotai/kimi-k2-instruct-0905 \n",
      "nv-mistralai/mistral-nemo-12b-instruct \n",
      "nvidia/embed-qa-4 \n",
      "nvidia/llama-3.1-nemoguard-8b-content-safety \n",
      "nvidia/llama-3.1-nemoguard-8b-topic-control \n",
      "nvidia/llama-3.1-nemotron-51b-instruct \n",
      "nvidia/llama-3.1-nemotron-70b-instruct \n",
      "nvidia/llama-3.1-nemotron-70b-reward \n",
      "nvidia/llama-3.1-nemotron-nano-4b-v1.1 \n",
      "nvidia/llama-3.1-nemotron-nano-8b-v1 \n",
      "nvidia/llama-3.1-nemotron-nano-vl-8b-v1 \n",
      "nvidia/llama-3.1-nemotron-safety-guard-8b-v3 \n",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1 \n",
      "nvidia/llama-3.2-nemoretriever-1b-vlm-embed-v1 \n",
      "nvidia/llama-3.2-nemoretriever-300m-embed-v1 \n",
      "nvidia/llama-3.2-nemoretriever-300m-embed-v2 \n",
      "nvidia/llama-3.2-nv-embedqa-1b-v1 \n",
      "nvidia/llama-3.2-nv-embedqa-1b-v2 \n",
      "nvidia/llama-3.3-nemotron-super-49b-v1 \n",
      "nvidia/llama-3.3-nemotron-super-49b-v1.5 \n",
      "nvidia/llama3-chatqa-1.5-70b \n",
      "nvidia/llama3-chatqa-1.5-8b \n",
      "nvidia/mistral-nemo-minitron-8b-8k-instruct \n",
      "nvidia/mistral-nemo-minitron-8b-base \n",
      "nvidia/nemoretriever-parse \n",
      "nvidia/nemotron-4-340b-instruct \n",
      "nvidia/nemotron-4-340b-reward \n",
      "nvidia/nemotron-4-mini-hindi-4b-instruct \n",
      "nvidia/nemotron-mini-4b-instruct \n",
      "nvidia/nemotron-nano-12b-v2-vl \n",
      "nvidia/nemotron-parse \n",
      "nvidia/neva-22b \n",
      "nvidia/nv-embed-v1 \n",
      "nvidia/nv-embedcode-7b-v1 \n",
      "nvidia/nv-embedqa-e5-v5 \n",
      "nvidia/nv-embedqa-mistral-7b-v2 \n",
      "nvidia/nvclip \n",
      "nvidia/nvidia-nemotron-nano-9b-v2 \n",
      "nvidia/riva-translate-4b-instruct \n",
      "nvidia/usdcode-llama-3.1-70b-instruct \n",
      "nvidia/vila \n",
      "openai/gpt-oss-120b \n",
      "openai/gpt-oss-120b \n",
      "openai/gpt-oss-20b \n",
      "openai/gpt-oss-20b \n",
      "opengpt-x/teuken-7b-instruct-commercial-v0.4 \n",
      "qwen/qwen2-7b-instruct \n",
      "qwen/qwen2.5-7b-instruct \n",
      "qwen/qwen2.5-coder-32b-instruct \n",
      "qwen/qwen2.5-coder-7b-instruct \n",
      "qwen/qwen3-235b-a22b \n",
      "qwen/qwen3-coder-480b-a35b-instruct \n",
      "qwen/qwen3-next-80b-a3b-instruct \n",
      "qwen/qwen3-next-80b-a3b-thinking \n",
      "qwen/qwq-32b \n",
      "rakuten/rakutenai-7b-chat \n",
      "rakuten/rakutenai-7b-instruct \n",
      "sarvamai/sarvam-m \n",
      "snowflake/arctic-embed-l \n",
      "speakleash/bielik-11b-v2.3-instruct \n",
      "speakleash/bielik-11b-v2.6-instruct \n",
      "stockmark/stockmark-2-100b-instruct \n",
      "thudm/chatglm3-6b \n",
      "tiiuae/falcon3-7b-instruct \n",
      "tokyotech-llm/llama-3-swallow-70b-instruct-v0.1 \n",
      "upstage/solar-10.7b-instruct \n",
      "utter-project/eurollm-9b-instruct \n",
      "writer/palmyra-creative-122b \n",
      "writer/palmyra-fin-70b-32k \n",
      "writer/palmyra-med-70b \n",
      "writer/palmyra-med-70b-32k \n",
      "yentinglin/llama-3-taiwan-70b-instruct \n",
      "zyphra/zamba2-7b-instruct \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"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\"\n",
    "url = \"https://integrate.api.nvidia.com/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    models = result.get(\"data\", [])\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"{model['id']} \")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code} - {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
